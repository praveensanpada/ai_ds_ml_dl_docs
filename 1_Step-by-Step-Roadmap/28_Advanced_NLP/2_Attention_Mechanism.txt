🎯 Advanced NLP Concepts
✅ 2) Attention Mechanism (IMP)
The Attention Mechanism allows models to focus on important parts of the input when generating an output — like how humans pay attention to key words in a sentence.

🤖 What Is Attention?
Instead of treating all words equally, attention helps the model weigh different words based on their relevance to the current task or token.

🧠 Real-Life Analogy:
Imagine you're reading a sentence:
"The cat that was hungry ate the fish."
Even though "cat" and "ate" are far apart, your brain knows they’re related — that’s attention at work.

✅ Why Use Attention?
Benefit	Description
📍 Focus	Prioritize important words
🧠 Long dependencies	Capture meaning across distant words
🔁 Parallelizable	Enables transformers to run efficiently
💡 Interpretability	Shows what parts of input influence output

🔧 Basic Attention Formula
For query (Q), key (K), and value (V) vectors:

✅ Real-Life NLP Applications
Task	How Attention Helps
Machine Translation	Focuses on relevant source words
Text Summarization	Highlights key sentences
Question Answering	Finds answers in long documents
Chatbots	Tracks user history for coherent replies

✅ Python Example: Visualizing Attention Using transformers
We’ll use a pretrained BERT model to see attention in action.
from transformers import BertTokenizer, BertModel
import torch

# Load model & tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)

# Sample text
sentence = "The cat chased the mouse across the room."
inputs = tokenizer(sentence, return_tensors='pt')
outputs = model(**inputs)

# Get attention scores
attention = outputs.attentions  # Tuple of attention layers
print(f"Total Layers: {len(attention)}, Shape of one head: {attention[0].shape}")



✅ Multi-Head Attention (Used in Transformers)
Instead of using one attention layer, we use multiple heads in parallel.

Why?
Each head learns different relationships between tokens
For example:
– Head 1 might focus on subject-object
– Head 2 might focus on adjectives



✅ Visual Summary of Attention

Sentence: The cat that was hungry ate the fish

           ↑            ↑
     Attention connects "cat" → "ate"

The attention layer gives high weights to the words that matter most.


✅ Summary: Attention Mechanism
Feature	Explanation
🧠 Idea	"Pay attention" to important input parts
🔁 Use	In RNNs (Bahdanau), Transformers (Vaswani)
🌐 Key Usage	BERT, GPT, T5, summarization, translation
⚙️ Key Concepts	Query, Key, Value, Score, Softmax
🔥 Core of	All state-of-the-art language models



✅ Types of Attention Mechanisms
Type	Description
Self-Attention	Word attends to all other words in the same seq
Global Attention	All inputs influence each output (seq2seq)
Local Attention	Focus on nearby words only
Bahdanau (Additive)	First attention for RNNs (2014)
Luong Attention	Improved dot-product variant (2015)


✅ Use Cases by Model
Model	Attention Used	Purpose
BERT	Self-Attention	Encode word meaning from both sides
GPT	Causal Self-Attention	Generate next token (auto-regressive)
T5	Encoder + Decoder Attn	Translation, summarization


✅ Would You Like:
A visualization of attention heads on your custom sentence?
To build a simple Transformer from scratch?
To apply attention in an RNN with Keras?

