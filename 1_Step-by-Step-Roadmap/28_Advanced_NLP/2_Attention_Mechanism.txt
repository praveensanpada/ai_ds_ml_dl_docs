ğŸ¯ Advanced NLP Concepts
âœ… 2) Attention Mechanism (IMP)
The Attention Mechanism allows models to focus on important parts of the input when generating an output â€” like how humans pay attention to key words in a sentence.

ğŸ¤– What Is Attention?
Instead of treating all words equally, attention helps the model weigh different words based on their relevance to the current task or token.

ğŸ§  Real-Life Analogy:
Imagine you're reading a sentence:
"The cat that was hungry ate the fish."
Even though "cat" and "ate" are far apart, your brain knows theyâ€™re related â€” thatâ€™s attention at work.

âœ… Why Use Attention?
Benefit	Description
ğŸ“ Focus	Prioritize important words
ğŸ§  Long dependencies	Capture meaning across distant words
ğŸ” Parallelizable	Enables transformers to run efficiently
ğŸ’¡ Interpretability	Shows what parts of input influence output

ğŸ”§ Basic Attention Formula
For query (Q), key (K), and value (V) vectors:

âœ… Real-Life NLP Applications
Task	How Attention Helps
Machine Translation	Focuses on relevant source words
Text Summarization	Highlights key sentences
Question Answering	Finds answers in long documents
Chatbots	Tracks user history for coherent replies

âœ… Python Example: Visualizing Attention Using transformers
Weâ€™ll use a pretrained BERT model to see attention in action.
from transformers import BertTokenizer, BertModel
import torch

# Load model & tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased', output_attentions=True)

# Sample text
sentence = "The cat chased the mouse across the room."
inputs = tokenizer(sentence, return_tensors='pt')
outputs = model(**inputs)

# Get attention scores
attention = outputs.attentions  # Tuple of attention layers
print(f"Total Layers: {len(attention)}, Shape of one head: {attention[0].shape}")



âœ… Multi-Head Attention (Used in Transformers)
Instead of using one attention layer, we use multiple heads in parallel.

Why?
Each head learns different relationships between tokens
For example:
â€“ Head 1 might focus on subject-object
â€“ Head 2 might focus on adjectives



âœ… Visual Summary of Attention

Sentence: The cat that was hungry ate the fish

           â†‘            â†‘
     Attention connects "cat" â†’ "ate"

The attention layer gives high weights to the words that matter most.


âœ… Summary: Attention Mechanism
Feature	Explanation
ğŸ§  Idea	"Pay attention" to important input parts
ğŸ” Use	In RNNs (Bahdanau), Transformers (Vaswani)
ğŸŒ Key Usage	BERT, GPT, T5, summarization, translation
âš™ï¸ Key Concepts	Query, Key, Value, Score, Softmax
ğŸ”¥ Core of	All state-of-the-art language models



âœ… Types of Attention Mechanisms
Type	Description
Self-Attention	Word attends to all other words in the same seq
Global Attention	All inputs influence each output (seq2seq)
Local Attention	Focus on nearby words only
Bahdanau (Additive)	First attention for RNNs (2014)
Luong Attention	Improved dot-product variant (2015)


âœ… Use Cases by Model
Model	Attention Used	Purpose
BERT	Self-Attention	Encode word meaning from both sides
GPT	Causal Self-Attention	Generate next token (auto-regressive)
T5	Encoder + Decoder Attn	Translation, summarization


âœ… Would You Like:
A visualization of attention heads on your custom sentence?
To build a simple Transformer from scratch?
To apply attention in an RNN with Keras?

