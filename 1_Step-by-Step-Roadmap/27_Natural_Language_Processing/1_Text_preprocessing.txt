ğŸ¯ Step 6: NLP (Natural Language Processing)
âœ… Basic NLP Concepts â€“ 1) Text Preprocessing (IMP)

ğŸ¤– What is Text Preprocessing?
Text preprocessing is the first step in NLP â€” preparing raw text for analysis or training a model.

It's like cleaning and organizing your text before feeding it to a machine learning or deep learning model.

ğŸ§  Why Itâ€™s Important?
Reduces noise and irrelevant info
Converts unstructured text into structured format
Improves model accuracy and efficiency

âœ… Real-Life Example: Sentiment Analysis on Movie Reviews
â€œThe movie was absolutely amazing and mind-blowing!â€
Raw text is messy â†’ we need to clean it:
Remove stopwords (e.g., was, and)
Convert to lowercase
Tokenize
Apply stemming/lemmatization

âœ… Key Preprocessing Techniques
Technique	Description
Tokenization	Breaks text into words or sentences
Stopwords Removal	Removes common filler words (e.g., is, the)
Stemming	Removes suffixes (e.g., â€œplayingâ€ â†’ â€œplayâ€)
Lemmatization	Converts word to base dictionary form (better than stemming)

âœ… Python Code: All Text Preprocessing Steps
import nltk
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

# Download NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Sample text
text = "The movie was absolutely amazing! It had thrilling action scenes and beautiful visuals."

# Lowercase
text = text.lower()

# Remove punctuation/numbers
text = re.sub(r'[^a-zA-Z\s]', '', text)

# Tokenization
tokens = word_tokenize(text)
print("ğŸ”¹ Tokens:", tokens)

# Stopword Removal
stop_words = set(stopwords.words('english'))
filtered = [word for word in tokens if word not in stop_words]
print("ğŸ”¹ Without Stopwords:", filtered)

# Stemming
stemmer = PorterStemmer()
stemmed = [stemmer.stem(word) for word in filtered]
print("ğŸ”¹ Stemmed Words:", stemmed)

# Lemmatization
lemmatizer = WordNetLemmatizer()
lemmatized = [lemmatizer.lemmatize(word) for word in filtered]
print("ğŸ”¹ Lemmatized Words:", lemmatized)

âœ… Output Example:
ğŸ”¹ Tokens: ['the', 'movie', 'was', 'absolutely', 'amazing', 'it', 'had', 'thrilling', 'action', 'scenes', 'and', 'beautiful', 'visuals']
ğŸ”¹ Without Stopwords: ['movie', 'absolutely', 'amazing', 'thrilling', 'action', 'scenes', 'beautiful', 'visuals']
ğŸ”¹ Stemmed Words: ['movi', 'absolut', 'amaz', 'thrill', 'action', 'scene', 'beauti', 'visual']
ğŸ”¹ Lemmatized Words: ['movie', 'absolutely', 'amazing', 'thrilling', 'action', 'scene', 'beautiful', 'visual']

âœ… Real-World Applications Using Preprocessing
Task	Preprocessing Role
Sentiment Analysis	Normalize reviews for polarity detection
Chatbots	Clean and parse user input
Resume Screening	Extract keywords and match job profiles
Spam Filtering	Convert email text into features for models

âœ… Summary Table
Step	Output/Goal
Tokenization	['this', 'is', 'cool']
Stopwords Removal	Removes ['is']
Stemming	'running' â†’ 'run'
Lemmatization	'better' â†’ 'good', 'was' â†’ 'be'
Final Output	Clean, short list of meaningful keywords





