üéØ Step 5: Deep Learning (DL)
‚úÖ 1) Perceptron ‚Äì Fundamentals of Neural Networks (IMP)

ü§ñ What is a Perceptron?
A Perceptron is the simplest neural network ‚Äî a single neuron that takes inputs, applies weights, sums them, and passes them through an activation function to produce output.

It's the foundation of neural networks, just like a brick in a wall üß±.

‚úÖ Perceptron Structure:
Inputs ‚Üí Weights ‚Üí Sum ‚Üí Activation ‚Üí Output
Mathematically:

üîπ Real-Life Example:
Predict if a student passes or fails based on:
Hours studied
Sleep hours

The perceptron takes those two inputs and predicts:
1 (Pass) or 0 (Fail)

‚úÖ Perceptron Python Code (From Scratch)
import numpy as np

# Step function
def step_function(z):
    return 1 if z > 0 else 0

# Perceptron class
class Perceptron:
    def __init__(self, input_size, lr=0.1):
        self.weights = np.zeros(input_size + 1)  # +1 for bias
        self.lr = lr

    def predict(self, x):
        x = np.insert(x, 0, 1)  # Add bias input
        z = np.dot(self.weights, x)
        return step_function(z)

    def train(self, X, y, epochs=10):
        for _ in range(epochs):
            for xi, target in zip(X, y):
                x_bias = np.insert(xi, 0, 1)
                prediction = self.predict(xi)
                self.weights += self.lr * (target - prediction) * x_bias

# Dataset: [study_hours, sleep_hours]
X = np.array([[2, 9], [1, 5], [3, 6], [4, 8]])
y = np.array([1, 0, 1, 1])  # Labels: Pass(1) / Fail(0)

model = Perceptron(input_size=2)
model.train(X, y)

# Test
print("Prediction (3 hrs study, 7 hrs sleep):", model.predict([3, 7]))

==================================================================================================================

üß† Key Points:
Component	Role
Input Layer	Raw features (e.g., study hours)
Weights	Learn importance of each input
Bias	Helps shift decision boundary
Activation	Decides output (0 or 1)

‚úÖ Limitations of Perceptron
Limitation	Solution
Only handles linear problems	Use multi-layer perceptron (MLP)
Step activation = Not differentiable	Use sigmoid, ReLU in deeper networks

‚úÖ Real-World Examples:
Task	Can Perceptron Solve?
Predict pass/fail (based on scores)	‚úÖ Yes (Linear)
Classify emails as spam/not	‚ùå No (needs non-linear model)
XOR logic gate	‚ùå No (non-linearly separable)

‚úÖ Summary
Term	Meaning
Perceptron	Basic building block of neural networks
Weights	Learn how important each input is
Bias	Shifts the decision boundary
Activation	Converts input to output

