ğŸ¯ Deep Learning Frameworks
âœ… 3) PyTorch (IMP)

ğŸ”¥ What is PyTorch?
PyTorch is an open-source deep learning framework developed by Facebook AI Research (FAIR).
It's popular for its flexibility, dynamic computation graphs, and simplicity â€” especially for research and custom model development.

âœ… Why PyTorch is Popular
Feature	Description
ğŸ” Dynamic Computation	Define model behavior at runtime â€” great for debugging
ğŸ§± Customization	Build any type of neural network with full Python control
ğŸ“ Loved by Researchers	Most research papers use PyTorch
ğŸ§  Pythonic	Intuitive and integrates with NumPy, SciPy, etc.
âš¡ GPU Acceleration	Works with CUDA & optimized for NVIDIA GPUs
ğŸ“¦ Strong Ecosystem	Tools: TorchVision, TorchText, PyTorch Lightning, etc

âœ… Real-Life Use Cases of PyTorch
Use Case	Description
ğŸ“· Image Classification	CNNs on datasets like CIFAR, ImageNet
ğŸ§¾ NLP & Transformers	BERT, GPT, LLMs â€“ most built using PyTorch
ğŸ§ Audio Analysis	Speaker detection, voice generation
ğŸ§  Research & Academia	Popular in labs for reproducibility and clarity
ğŸ¤– Reinforcement Learning (RL)	Agents, gym environments, Q-learning

âœ… PyTorch Key Components
Component	Description
torch.Tensor	Like NumPy arrays, but with GPU acceleration
autograd	Automatic differentiation (for backprop)
nn.Module	Build neural networks (your own layers)
optimizer	Weight update methods (SGD, Adam, etc.)
loss functions	MSE, CrossEntropy, etc.
torchvision	Dataset + image utils

âœ… Basic PyTorch Neural Network Example
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X = StandardScaler().fit_transform(X)

# Convert to PyTorch tensors
X = torch.tensor(X, dtype=torch.float32)
y = torch.tensor(y, dtype=torch.long)

# Train/test split
X_train, X_test = X[:120], X[120:]
y_train, y_test = y[:120], y[120:]

# Build model
class NeuralNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(4, 16)
        self.fc2 = nn.Linear(16, 3)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

model = NeuralNet()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Train loop
for epoch in range(100):
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()

# Test accuracy
with torch.no_grad():
    predictions = model(X_test).argmax(dim=1)
    acc = (predictions == y_test).float().mean()
    print("Test Accuracy:", acc.item())


âœ… Model Workflow in PyTorch
Load & preprocess data
Create model (nn.Module)
Define loss function
Choose optimizer
Forward pass â†’ compute loss
Backward pass â†’ compute gradients
Update weights using optimizer

âœ… PyTorch vs TensorFlow/Keras
Feature	PyTorch	TensorFlow/Keras
ğŸ” Execution Mode	Dynamic (eager)	Static (graph mode, optional eager)
ğŸ§± Model Building	More control, manual	Simpler, less boilerplate
ğŸ“ Research	Most popular	More used in production
ğŸ§© Libraries	TorchVision, TorchText, PyG	TF Hub, TF Lite, TF.js
ğŸ“¦ Deployment	TorchScript, ONNX	TF Lite, TensorFlow Serving

âœ… Summary Table
Topic	PyTorch Feature
Core Data Type	torch.Tensor
Model	Subclass nn.Module, define forward()
Optimizers	torch.optim.Adam, SGD, etc.
Loss Functions	nn.CrossEntropyLoss, MSELoss, etc.
Training Style	Manual training loop (but customizable)
Use Case	Custom models, deep research, transformers

âœ… Real Projects Built with PyTorch
Project	Models Used
Image classifier on CIFAR-10	CNN with Conv2D, Pooling, ReLU
Sentiment analysis on tweets	LSTM + Embedding + Dense
Object detection	Faster R-CNN, YOLO (TorchVision)
BERT fine-tuning (NLP)	Transformers with Hugging Face
GAN image generator	Subclassed PyTorch nn.Module



